# AI Regulation



## Introduction

Artificial Intelligence (AI) regulation is a crucial topic for business today. AI rapid adoption has triggered discussions on how to regulate its use to ensure ethical use and to manage risks.



## Current Landscape of AI Regulation



### Global Overview

Today, several countries are discussing AI regulation in some shape or form. Efforts such as the EU AI Act and the UK pro-innovation regulatory approach are examples.

### EU AI Act ([EU 2024/1689](https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX%3A32024R1689))

**Timeline:**

![image-20240902155015745](C:\Users\marcec\AppData\Roaming\Typora\typora-user-images\image-20240902155015745.png)

- April 2021: EU publish proposal for AI regulation 
- December 2022: EU Council adopted common position.
- June 2024: [AI act signed](https://www.europarl.europa.eu/RegData/etudes/BRIE/2021/698792/EPRS_BRI(2021)698792_EN.pdf)
- July 2024: AI Act published in the EU official journey
- August 2024: AI act enter in force.

**Risk-based approach:**

![image-20240902152845834](C:\Users\marcec\AppData\Roaming\Typora\typora-user-images\image-20240902152845834.png)

**Unacceptable risk**:  represents a clear threat to people's safety such as AI system that deploy harmful manipulative 'subliminal techniques, exploit specific vulnerable groups (physical or mental disability), used by public authorities, or on their behalf, for social scoring purposes,  or 'real-time' remote biometric identification systems in publicly accessible spaces for law enforcement purposes, except in a limited number of cases (e.g. threat of life, terrorist attack, missing children). 



**High risk**: must comply with strict requirements regarding risk management, data governance, documentation, and conformity assessment. Example of sectors in scope of high risk systems are: critical infrastructure, HR process, safety components of products, systems determining credit worthiness and various governmental domains such migration, border control and justice and democratic processes.

**Limited risk**: systems that interact with humans (i.e. chatbots), emotion recognition systems, biometric categorisation systems, and AI systems that generate or manipulate image, audio or video content (i.e. deepfakes), would be subject to a limited set of transparency obligations. 

**Minimal risk**: AI system developed and used in the EU without conforming to any additional legal obligations. However, the AI act envisaged the creation of codes of conduct to encourage providers of non-high-risk AI systems to apply the mandatory requirements for high-risk AI systems voluntarily.



**Who is impacted:**

- Both public and private actors as long as AI system is placed on the EU market or its use affects people located in EU. Following roles exists:
  - **Providers**: Person, institution or body that develops an AI system.
  - **Importers**: person established in the union that placed on the market or put into service an AI system
  - **User**: any natural or legal person using an AI system.
  - **Distributors**: any person in the supply chain, other than providers or the importer, that distribute  an AI available on the EU market.
  - Note: AI systems placed on the market, put into service, or used by public and private entities for military, defence or national security purposes, are excluded from the scope. In addition to service for the sole purpose of scientific research and development.



**Definitions:**

![image-20240903083541689](C:\Users\marcec\AppData\Roaming\Typora\typora-user-images\image-20240903083541689.png)

- **AI system**: machine learning, logic and knowledge base system and statistical approaches.

> An AI system is a machine-based system designed to operate with varying levels of autonomy and that may exhibit adaptiveness after deployment and that, for explicit or implicit objectives, infers, from the input it receives, how to generate outputs such as predictions, content, recommendations, or decisions that can influence physical or virtual environments.



- **General purpose artificial intelligence (GPAI) models**: 

> GPAI are models trained with a large amount of data using self-supervision at scale', that display 'significant generality' and are 'capable to competently perform a wide range of distinct tasks' and 'can be integrated into a variety of downstream systems or applications'. 



**Costs:**

Cost of compliance: conformity assessment with need to involve collaboration across the organization. 

**TODO**: compliance cost example?

Implication of Non-compliance: fines and penalties (2-6% of total worldwide annual turnover depending on the severity) 



**Strategy:**

- Compliance checks on AI lifecycle (TODO: check AI lifecycle)
- Access critical "missing" requirements
- AI risk management methods
- Rollout, compliance and oversight of the AI program
- Learning and development programs to train employees on AI ethical/regulatory (e.g. escalation procedures)
- Translate AI framework to fit organization(e,g, risk categories, RACI matrix, policies, procedures, workflows, quality assurance/quality improvement )



### Regional Differences

In this section, we are highlight differences in regulatory approaches between regions, such as EU comprehensive legal framework and specific countries approaches to AI regulation, such as Norway.



## Key Regulatory Challenges and Considerations

- **Ethical Use and Accountability:** Address the importance of ethical AI use, transparency, and accountability in AI systems.
- **Data Privacy and Security:**  Discuss how AI regulation intersects with data privacy laws and the implications for businesses.
- **Compliance and Costs**: Explain the potential compliance challenges and costs associated with navigating a complex regulatory environment.



## Impact on Business 

- **Operational Implications**: How AI regulation might affect business operations, including potential impacts on innovation, efficiency, and competitiveness.
- **Risk Management**: Strategies for managing risks associated with AI, such as implementing robust internal governance policies and engaging with legal experts.
- 

## **Future Trends and Developments**

- **Emerging Regulations**: Insights into upcoming regulatory changes and how businesses can prepare for them.

- **International Cooperation**: The importance of international collaboration in AI regulation and its potential impact on global business operation

  

## Conclusion

**Key points:**

- 



## References

- [The EUâ€™s AI Act and How Companies Can Achieve Compliance](https://hbr.org/2024/02/the-eus-ai-act-and-how-companies-can-achieve-compliance)
- [Briefing: Artificial intelligence act](https://www.europarl.europa.eu/RegData/etudes/BRIE/2021/698792/EPRS_BRI(2021)698792_EN.pdf)
- [[PDF ]Regulation (EU) 2024/1689 - Artificial Intelligence Act](https://eur-lex.europa.eu/legal-content/EN/TXT/PDF/?uri=OJ:L_202401689)

PS: Text written with help from AI.